kg_description_template:
  system: |-
    您是一名助手，负责从非结构化文本中提取结构化信息。
    用户将向您提供一个 Kaggle 竞赛描述，您需要从中提取具体细节。
    对于数据集，竞赛可能不包括数据集的详细信息。用户已阅读数据集并向您提供相关信息，请将其包含在您的回复中。
    请以 Json 格式回答，使用以下模式：
    {
      "竞赛类型": "竞赛的类型，例如：'分类'、'回归'、'聚类'、'预测'、'时间序列预测'",
      "竞赛描述": "竞赛的简要描述",
      "目标描述": "目标变量的描述",
      "竞赛特征": "竞赛背景中涉及的整体特征的两行描述。"
      "提交规范": "模型输出的提交规范和示例提交 csv 描述。"
      "每个样本的提交通道数": "每个样本输出的通道数，例如：回归为 1，N 类分类为 N 个概率等。一个整数。如果未指定，则为 1。"
      "评估指标描述": "评估中使用的指标的简要描述。请注意，如果 `evaluation_metric_direction` 为 True，则表示值越高越好；如果为 False，则表示值越低越好。"
    }
    由于这些可能是数据中非常相似的列名，例如 one_hot_encoded 列，您可以使用一些正则表达式将它们分组。


  user: |-
    竞赛描述：
    {{ competition_descriptions }}
    原始数据信息：
    {{ raw_data_information }}
    评估指标方向：
    {{ evaluation_metric_direction }}

kg_background: |-
  您正在解决数据科学任务，竞赛类型是 {{ competition_type }}。
  竞赛描述是：{{competition_description}}。 
  
  我们在文件 train.py 中提供了一个整体脚本。用户将运行 train.py 脚本以及多个特征和模型脚本来训练多个模型，以在此任务中获得良好的性能。

  train.py 脚本如下：
  ```python
  {{ train_script }}
  ```
  
  我们的管道最终输出来自最多四个模型的集成。每个模型都在数据的不同子集上进行训练。
  四种模型类型是：XGBoost、RandomForest、LightGBM 和神经网络（一个 Pytorch 模型）。
  关于神经网络模型，您可以尝试不同的架构和超参数来提高性能。您甚至可以使用 pytorch 模型来集成其他三种类型的模型。尝试在神经网络模型上打开思路。
  
  数据来自竞赛数据集，重点关注 {{ competition_features }} 中的相关属性。

  用户首先为每个模型设计和实现特征书。特征书是多个特征和特征组的组合。
  特征书由以下部分构成：
  - 原始特征：原始特征是数据集中的原始特征。
  - 生成特征：生成特征是根据原始特征通过某些公式计算得出的特征。计算应与某些物理或逻辑含义一致。不要仅仅对原始特征应用一些数字操作。
  - 特征组：特征组是来自原始特征的预处理特征组，如归一化、独热编码等。
  特征或特征组在以下部分中定义：
  - 名称：特征或特征组的名称。
  - 描述：特征或特征组的描述。
  - 公式：特征或特征组的公式。
  - 变量：公式中使用的变量列表。注意：变量应是数据集中具体的特征。请确保特征名称与数据集中的特征名称完全相同。
  
  对于每个模型，用户将在单独的脚本中设计和实现模型。
  模型在以下部分中定义：
  - 名称：模型的名称。
  - 描述：模型的描述。
  - 架构：模型的详细架构，例如神经网络层或树结构。
  - 模型类型：模型的类型，应为 ["XGBoost"、"RandomForest"、"LightGBM"、"NN"] 之一。
  模型应清晰详细地记录其架构和超参数。

  用户通过采用与特征相关或模型相关的行动项目之一，迭代地优化性能：
  - 特征相关：
    - "特征工程"：用户将设计几个新任务并实现几个新特征。新特征可能只影响使用所有特征书的模型。
    - "特征处理"：用户将设计一个新任务来处理特征书，如归一化或独热编码，以提高模型性能。任何借助深度模型的处理均不包括在此任务中。
  - 模型相关：
    - "模型特征选择"：用户将修改一个模型，从特征书中选择部分特征，以提高模型性能。
    - "模型调优"：用户将调整 XGBoost、RandomForest 或 LightGBM 的超参数，或构建或改进 NN 模型，以提高模型性能。 
  注意：您可以在训练模型时使用某些库自动优化模型的超参数。由于我们没有太多时间训练模型，请使用少量试验来优化超参数。 
  我们的验证集拆分不是确定性的，因此当您使用超参数调整时，可以合并训练和验证并使用交叉验证方法来调整超参数。
  一旦确定最佳模型参数，应在所有训练和验证集上重新训练模型，以获得最终模型。

  对于每个循环，您需要帮助用户决定选择哪个行动项目，并提供相应的代码来实现该行动项目。

kg_feature_interface: |-
  您的代码应包含几个部分：
  1. 导入部分：导入必要的库。
  2. 包含特征工程逻辑的类。
    该类应具有以下方法：
      - 拟合：该方法应将特征工程模型拟合到训练数据。
      - 转换：该方法应转换输入数据并返回。
    对于某些任务，如生成新特征，拟合方法可能不是必需的。请将此函数作为无操作传递。
  3. 一个名为 feature_engineering_cls 的变量，包含类名。
  '拟合'的输入是 pandas 数据框中的训练数据，'转换'的输入是 pandas 数据框中的要转换的数据。
  原始列应从返回的 DataFrame 中排除。

  注意：由于我们有一个非常大的数据集，特征工程应该高效快速。否则，请充分利用多处理或并行计算来加速特征工程过程！

  异常处理将在外部管理，因此请避免在代码中使用 try-except 块。用户将处理出现的任何异常并根据需要提供反馈。
  
  feat_eng 函数可以是以下内容之一：
  - 特征工程：此函数根据现有原始数据计算一个新特征。
  - 特征处理：此函数处理现有原始数据，如归一化或独热编码，并以 pandas DataFrame 形式返回处理后的数据。

  以下是您的 Python 代码应如何构建的示例：
  ```python
  import pandas as pd

  class FeatureEngineeringName:
      def fit(self, train_df: pd.DataFrame):
          """
          将特征工程模型拟合到训练数据。 
          例如，对于独热编码，这将涉及将编码器拟合到训练数据。
          对于特征缩放，这将涉及将缩放器拟合到训练数据。
          """
          return self

      def transform(self, X: pd.DataFrame):
          """
          转换输入数据。
          """
          return X
          return X.mean(axis=1).to_frame("mean_feature") # 示例特征工程
          return X.fillna(0) # 示例特征处理

  feature_engineering_cls = FeatureEngineeringName
  ```

  注意事项：
  0. 我已经完成了编码标签处理过程，因此请避免在将来的任何独热编码或类似操作。请专注于有针对性和高效的特征工程技术，例如归一化浮点型特征、基于特定类别的过滤或其他可以快速实施和测试的简明转换。同时，确保输出 DataFrame 的索引与原始 DataFrame 的索引匹配，并且列数在训练、验证和测试集之间保持一致。
  1. 确保您的代码满足这些要求，并生成仅包含新工程特征的特征工程 DataFrame，以符合用户的数据和目标。
  2. 确保输出 DataFrame 的索引与原始 DataFrame 的索引匹配。例如：
    错误：`normalized_df = pd.DataFrame(normalized_features, columns=X.columns)`
    正确：`normalized_df = pd.DataFrame(normalized_features, columns=X.columns, index=X.index)`
  3. 确保在特征工程后，训练、验证和测试集之间的列数保持一致。例如，在训练集上拟合 PCA，并将相同的转换应用于验证和测试集，以保持列数一致，使用独热编码器也可能导致列数不一致。
  4. 确保新特征的生成不会大幅增加列数，因为这会减慢数据处理速度。例如，避免对所有特征创建成对交互，因为这会导致列数呈平方级数增加。
  5. 避免引发 `ValueError` 或可能中断主程序流程的其他异常。代码不应包括可能导致 `ValueError` 的检查。相反，专注于编写健壮且容错的特征工程函数，能够优雅地处理边缘情况和缺失数据，而不会停止程序。
  6. 可以过滤特定类别的特征，并对这些类别应用处理。例如，可以对浮点型特征应用归一化，但不应对独热编码特征进行此类处理。
  7. 您正在参加 Kaggle 竞赛，需要快速、高效的小型数据工程想法。您的建议应避免不必要的复杂性或过长的处理时间。专注于提供简明、有效的转换或预处理步骤，以最小的资源消耗提高模型性能。请提出可以快速实施和测试的清晰、针对性的方法。

kg_model_interface: |-
  您的代码应包含几个部分：
  1. 导入部分：导入必要的库。
  2. 一个名为 fit() 的函数，用于训练模型并返回训练好的模型。
    该函数应接受以下参数：
      - X_train：训练特征，格式为 pandas DataFrame。
      - y_train：训练标签，格式为 pandas Series。
      - X_valid：验证特征，格式为 pandas DataFrame。
      - y_valid：验证标签，格式为 pandas Series。
    该函数应返回训练好的模型。
  3. 一个名为 predict() 的函数，用于使用训练好的模型进行预测。 
    该函数应接受以下参数：
      - model：训练好的模型。
      - X：特征，格式为 pandas DataFrame。
    该函数应返回 numpy.ndarray 格式的预测概率或布尔预测。
    请参考 train.py 脚本以验证输出是类标签还是概率！

  以下是您的 Python 代码应如何构建的示例：

  {% if tag == "XGBoost" or tag is none %}
  对于 XGBoost：
  ```python
  import pandas as pd
  import numpy as np
  import xgboost
  from xgboost import DMatrix

  def fit(
      X_train: pd.DataFrame, y_train: pd.Series, X_valid: pd.DataFrame, y_valid: pd.Series
  ) -> xgboost.Booster:
      dtrain = DMatrix(X_train, label=y_train)
      dvalid = DMatrix(X_valid, label=y_valid)
      params = ...  # 设置 XGBoost 模型的参数
      model = xgboost.train(params, dtrain, num_boost_round=100)
      y_pred = model.predict(dvalid)

      accuracy = ...  # 计算准确率
      return model


  def predict(model: xgboost.Booster, X: pd.DataFrame) -> np.ndarray:
      dtest = DMatrix(X)
      y_pred = model.predict(dtest)

      return y_pred
  ```
  {% endif %}
  {% if tag == "RandomForest" or tag is none %}
  对于 RandomForest：
  ```python
  import pandas as pd
  import numpy as np
  from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
  from sklearn.metrics import accuracy_score

  def fit(
      X_train: pd.DataFrame, y_train: pd.Series, X_valid: pd.DataFrame, y_valid: pd.Series
  ) -> RandomForestClassifier | RandomForestRegressor:
      model = RandomForestClassifier(...)  # 分类任务
      model = RandomForestRegressor(...)  # 回归任务
      model.fit(X_train, y_train, ...) # 训练模型

      return model


  def predict(model: RandomForestClassifier | RandomForestRegressor, X: pd.DataFrame) -> np.ndarray:
      y_pred = model.predict(X)

      return y_pred
  ```
  {% endif %}
  {% if tag == "LightGBM" or tag is none %}
  对于 LightGBM：
  ```python
  import pandas as pd
  import numpy as np
  from lightgbm import LGBMClassifier, LGBMRegressor

  def fit(
      X_train: pd.DataFrame, y_train: pd.Series, X_valid: pd.DataFrame, y_valid: pd.Series
  ) -> LGBMClassifier | LGBMRegressor:
      model = LGBMClassifier(...)  # 分类任务，请在此处添加参数
      model = LGBMRegressor(...)  # 回归任务，请在此处添加参数

      model.fit(X=X_train, y=y_train, eval_set=[(X_valid, y_valid)])
      return model


  def predict(model: LGBMClassifier | LGBMRegressor, X: pd.DataFrame) -> np.ndarray:
      y_pred = model.predict(X)

      return y_pred
  ```
  {% endif %}
  {% if tag == "NN" or tag is none %}
  对于神经网络：
  ```python
  import pandas as pd
  import numpy as np
  import torch
  from torch.utils.data import DataLoader, TensorDataset


  class NNModel(torch.nn.Module):
      def __init__(self):
          super(Model, self).__init__()
          # 在此定义您的模型

      def forward(self, x):
          # 定义前向传播
          return x

  def fit(X_train: pd.DataFrame, y_train: pd.DataFrame, X_valid: pd.DataFrame, y_valid: pd.DataFrame) -> torch.nn.Module:
      model = NNModel()  # 初始化模型，您可以编写自己的模型类

      optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  # 示例优化器，您可以使用任何优化器
      criterion = torch.nn.CrossEntropyLoss()  # 示例损失函数，您可以使用任何损失函数

      train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)
      valid_loader = DataLoader(TensorDataset(X_valid, y_valid), batch_size=64, shuffle=False)

      # 示例训练循环，您可以根据需要自定义此循环
      for epoch in range(10):
          model.train()
          for X_batch, y_batch in train_loader:
              optimizer.zero_grad()
              outputs = model(X_batch)
              loss = criterion(outputs, y_batch)
              loss.backward()
              optimizer.step()

          model.eval()
          y_pred = []
          with torch.no_grad():
              for X_batch, _ in valid_loader:
                  outputs = model(X_batch)
                  y_pred.extend(outputs.squeeze().tolist())

          y_pred = torch.tensor(y_pred)
          accuracy = (y_pred == y_valid).float().mean()
          # 您可以根据验证结果提前停止，请根据需要自定义
      return model


  def predict(model: torch.nn.Module, X: pd.DataFrame) -> np.ndarray:
      X = torch.tensor(X.values).float()
      model.eval()
      with torch.no_grad():
          y_pred = model(X).squeeze().numpy()

      return y_pred
  ```
  {% endif %}

kg_feature_simulator: |-
  您提供的数据预处理方法将用于通过处理数据、将结果与其他特征连接以及在训练模型之前删除不必要的特征来准备数据。 
  然后，处理后的数据将用于模型训练和预测。
  
  用户将使用您的数据预处理方法执行以下步骤：
  1. 执行您的 Python 文件以处理数据。（您需要做的）
  2. 将处理后的特征与其他特征和原始数据连接。
  3. 在训练模型之前删除任何不必要的特征。
  4. 使用处理后的数据训练模型，例如 LightGBM、CatBoost、LSTM 或简单的 PyTorch 模型。
  5. 评估数据预处理方法的性能并提供反馈。

kg_feature_output_format: |-
  输出应为一个 pandas DataFrame，包含新特征。列应为新特征，行应对应于输入 DataFrame 中的样本数量。
  输出数据框信息示例:
  <class 'pandas.core.frame.DataFrame'>
  索引: {与输入 DataFrame 相同}
  数据列（总计 N 列）:
  #   列名      数据类型  
  ---  ------      -----  
  0   feature_name_0   float64
  1   feature_name_1  float64
  数据类型：float64(N)
  内存使用情况：{输出 DataFrame 的内存使用情况}

kg_model_output_format: |-
  对于与模型相关的任务，输出应为具有适当数量预测的 np.ndarray。 
  请参考 train.py 脚本以验证输出是类标签还是概率！
  {% if channel == 1 %}
  对于每个样本，输出应为单个值（例如，如果有 8 个样本，则为 (8, 1)）。
  {% else %}
  对于每个样本，输出应为多个值，数量为 {{ channel }}（例如，如果有 8 个样本，则为 (8, {{ channel }})）。
  {% endif %}
  
kg_model_simulator: |-
  模型将在竞赛数据集上进行训练，并评估其预测目标的能力。 
  使用准确率和 AUC-ROC 等指标来评估模型性能。 
  模型性能将根据评估结果的反馈进行迭代改进。
  您的输出应遵循一些提交竞赛的要求：
  {{ submission_specifications }}