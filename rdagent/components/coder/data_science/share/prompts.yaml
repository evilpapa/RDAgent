dump_model_coder:
  guideline: |-
    请在第一次运行时将模型保存到 "models/" 子文件夹中，并在脚本重新运行时执行推理，而无需重新训练模型。
    如果训练数据生成的参数可能在测试数据推理中需要，请将它们保存到 "models/" 子文件夹中。
    如果未提供测试集，请保留部分数据作为测试集，并将生成的测试文件保存到 "models/" 子文件夹中，以用于提交和推理。
    确保所需文件（如 submission.csv 和 scores.csv）可以通过加载保存的模型和测试数据文件直接创建，而无需模型训练步骤。

dump_model_eval:
  system: |-
    您是一名数据科学家，负责评估代码生成。您已开发出一个 Kaggle 比赛代码，可以生成提交文件。
    代码应遵循以下指南：
    {% include "components.coder.data_science.share.prompts:dump_model_coder.guideline" %}

    您将收到以下信息：
    - 实现的代码
    - 运行代码的标准输出
    - "models/" 子文件夹中的文件列表
    - 在训练和推理过程中生成的 scores.csv 文件（如果存在）

    重点关注以下方面：
    - 检查代码是否将模型保存到 "models/" 子文件夹中。
    - 检查代码是否在未指定测试数据时将测试数据保存到 "models/" 子文件夹中。
    - 确保代码重新运行时跳过训练过程，并从 "models/" 子文件夹加载模型以直接推理。
      - 验证输出中是否没有训练活动。
    - 确保即使通过加载保存的模型跳过模型训练，文件如 scores.csv 和 submission.csv 仍然正确创建。
    - 模型性能应保持一致，不应在训练和推理之间出现不合理的变化。

    请以以下 JSON 格式和顺序反馈您的意见
    ```json
    {
        "execution": "描述代码是否成功执行。包括遇到的任何错误或问题，并附上所有错误消息和完整的回溯详细信息，不要总结或省略任何信息。仔细检查标准输出以确保代码重新运行时跳过训练过程，并从 'models/' 子文件夹加载模型以直接推理。附上让您认为模型在重新运行代码时仍在重新训练的信息。",
        "return_checking": "验证生成的文件是否包含必要文件。确保 scores.csv 文件在训练和推理之间不会出现不合理的变化",
        "code": "代码已明确将模型保存到 'models/' 子文件夹；当模型文件已存在于 'models/' 子文件夹中时，代码将明确跳过训练过程。",
        "final_decision": <true 或 false 的布尔值；仅在确保代码将模型保存到 'models/' 子文件夹中，并且脚本重新运行时执行推理而无需重新训练模型时返回 true。>
    }
    ```

  user: |-
    ------------ The implemented code ------------ 
    {{code}}

    ------------ The stdout from running the code ------------ 
    {{stdout}}

    ------------ The file list in "models/" subfolder ------------
    {% for f in model_folder_files %}
    - {{ f }}
    {% endfor %}

    ------------ The scores.csv file generated ------------
    # Training:
    {{scores_content_before}}

    # Inference:
    {{scores_content_after}}


docdev:
  system: |-
    {% include "scenarios.data_science.share:scen.role" %}  Your task is to create documentation for a data science solution.

    You will be given:
    - a list of files in the folder.
    - content from some important files.

    Please explain the trained models in the "models/" folder. The training and inference processes are detailed in the `main.py` file. The models' evaluation results are in `scores.csv`. Please respond with a markdown file that includes the following information:
    - Explain the purpose of each model. If some models are part of a group (like those from cross-validation), describe them together.
    - Provide key details for each model group:
      - Important training parameters
      - Model details
      - Performance of each model

    Be brief. Mention the file path when you introduce files.
    Don't introduce anything other than models.

    {% include "utils.agent.tpl:MarkdownOut" %}

  user: |-
    --------------- The file list in the workspace ---------------
    {% for f in file_li %}
    - {{ f }}
    {% endfor %}

    --------------- File content of each file ---------------
    {% for fname, content in key_files.items() %}
    File Path: {{fname}}
    ```
    {{content}}
    ```
    {% endfor %}

